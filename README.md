# Adversarial-Attack-Demo
Adversarial Attack Detection App

Project Overview

This project is an interactive web application that demonstrates Evasion Attacks on a Convolutional Neural Network (CNN). Using the Fast Gradient Sign Method (FGSM), the app allows users to upload handwritten digits and visualize how invisible noise can trick the AI into making incorrect predictions.

Files

train_model.py: Script to train the CNN on MNIST and evaluate accuracy (Reach ~98%).

app.py: Flask backend processing images and running the FGSM attack.

templates/index.html: Frontend UI with Chart.js visualization.

mnist_cnn.pt: Saved model weights (generated by training).

Grading Criteria Met

Web-App Functionality (20 pts): Fully functional upload, attack logic, and Chart.js visualization.

Model Performance (5 pts): Uses a CNN with >98% accuracy on MNIST. Training script includes evaluation metrics.

Documentation (10 pts): Modular code structure and clear setup guide below.

How to Run (macOS/Linux/Windows)

1. Setup Environment

# Create virtual environment (Mac/Linux)
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install flask torch torchvision numpy pillow


2. Train Model

python train_model.py


Wait for "Model saved to mnist_cnn.pt"

3. Run Web App

python app.py


Open browser at http://127.0.0.1:5000
